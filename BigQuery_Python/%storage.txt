# Read from Google Cloud Storage as string / text file:

%storage read --object 'gs://<Bucket>/<file>' --<python_variable>
get_iptyhon().magic(u'storage read --object<full_gcs_path> --variable <ptyhon_variable>')


# Save dataframe to Google Cloud Storage as csv:
# First you should save the the csv in the vm and the copy the file from the vm to GCS

df_piv.to_csv(<file_name.csv>, index = False) # We do not need the index
get_ipython().system('gsutil cp ' + <file_name.csv> + ' ' + <gcs/path/>)


# Copy object in Google Cloud Storage:

import google.datalab.storage as storage

bucket = '<top_level_bucket>' e.g 'hpatel'
old_key = '<path_to_file_to_be_copied>' e.g 'data_raw/file_name.csv'
new_key = '<path_to_new_location_of_file>' e.g 'data_clean/file_name.csv'

storage.Object(bucket, old_key).copy_to(new_key)


# Delete object in Google Cloud Storage:

import google.datalab.storage as storage

bucket = '<top_level_bucket>' e.g 'hpatel'
old_key = '<path_to_file_to_be_deleted>' e.g 'data_raw/file_name.csv'

storage.Object(bucket,old_key).delete()
